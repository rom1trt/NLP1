{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK TOKENIZER AND TF-IDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/assil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tokenizer import tokenizer\n",
    "from vectorizer import vectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../_data/Reviews.csv') # Loading the dataset\n",
    "X, y = data['Text'], data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING : only select first 20000 samples\n",
    "# X, y = X[:20000], y[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents = tokenizer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/assil/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, vect = vectorizer(tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words in the dataset\n",
      "['0' '00' '000' '0000' '000001' '00001' '000013' '0000soo' '0001'\n",
      " '000111052']\n",
      "Top 10 least frequent words in the dataset\n",
      "['¾' 'â' 'çay' 'çaykur' 'çelem' 'être' 'île' 'ît' 'ø' 'þ']\n"
     ]
    }
   ],
   "source": [
    "# most frequent words\n",
    "print(\"Top 10 most frequent words in the dataset\")\n",
    "print(vect.get_feature_names_out()[:10])\n",
    "\n",
    "# least frequent words\n",
    "print(\"Top 10 least frequent words in the dataset\")\n",
    "print(vect.get_feature_names_out()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454763, 120297) (113691, 120297) (454763,) (113691,)\n",
      "  (0, 94440)\t0.2476460880247669\n",
      "  (0, 107570)\t0.3272463189045511\n",
      "  (0, 60950)\t0.6275233729847669\n",
      "  (0, 31243)\t0.34779816409007885\n",
      "  (0, 25567)\t0.17616947504652833\n",
      "  (0, 79631)\t0.26178338973622206\n",
      "  (0, 25422)\t0.10376272503403408\n",
      "  (0, 106024)\t0.11820467973703584\n",
      "  (0, 40683)\t0.17006292327236913\n",
      "  (0, 78761)\t0.16403902113711577\n",
      "  (0, 69776)\t0.21071725355716414\n",
      "  (0, 107849)\t0.10560844196570854\n",
      "  (0, 76937)\t0.11164550726217257\n",
      "  (0, 108271)\t0.08235972398533828\n",
      "  (0, 61826)\t0.1684136904878422\n",
      "  (0, 61973)\t0.08010732780470854\n",
      "  (0, 66932)\t0.12302984811317055\n",
      "  (0, 55845)\t0.10944036920045735\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "### Model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  880     0     1    12  9433]\n",
      " [   87     5     1    11  5751]\n",
      " [   45     1     8    25  8406]\n",
      " [   25     4     4   135 15955]\n",
      " [   36    14    10    33 72809]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.09      0.15     10326\n",
      "           2       0.21      0.00      0.00      5855\n",
      "           3       0.33      0.00      0.00      8485\n",
      "           4       0.62      0.01      0.02     16123\n",
      "           5       0.65      1.00      0.79     72902\n",
      "\n",
      "    accuracy                           0.65    113691\n",
      "   macro avg       0.53      0.22      0.19    113691\n",
      "weighted avg       0.61      0.65      0.52    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "naive_bayes = nb.fit(X_train, y_train)\n",
    "predicted = naive_bayes.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "example = '''\n",
    "awful\n",
    "'''\n",
    "\n",
    "# tokenize and vectorize it, then try to predict\n",
    "test = tokenizer([example])\n",
    "test_tfidf = vect.transform(test)\n",
    "print(naive_bayes.predict(test_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
