{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n- Term Frequency (TF) : C'est la fréquence d'un terme dans un document donné. \\n                        Elle est calculée en comptant le nombre d'occurrences du terme dans le document \\n                        et en la divisant par le nombre total de mots dans le document.\\n- Inverse Document Frequency (IDF): C'est une mesure de l'importance d'un terme dans l'ensemble du corpus. \\n                                    Elle est calculée en prenant le logarithme du nombre total de documents \\n                                    divisé par le nombre de documents contenant le terme en question. \\n                                    Il diminue la pondération des termes qui apparaissent dans de nombreux documents.\\n- TF-IDF : C'est le produit de TF et IDF. \\n           Cela permet de mettre en évidence les termes qui sont importants dans un document donné\\n           mais relativement rares dans le reste du corpus.\\n\\n\\n- Recherche d'information: les termes les plus pertinents dans un document par rapport à une requête donnée.\\n- Classification de texte: En convertissant les documents en vecteurs TF-IDF,\\n                           on peut les utiliser comme entrées pour des algorithmes de classification.\\n- Extraction de mots-clés: Les termes ayant les scores TF-IDF les plus élevés peuvent être considérés\\n                           comme des mots-clés représentatifs du document.\\n- Résumé automatique: TF-IDF peut aider à identifier les phrases les plus importantes d'un document\\n                       pour en générer un résumé.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Term Frequency (TF) : C'est la fréquence d'un terme dans un document donné. \n",
    "                        Elle est calculée en comptant le nombre d'occurrences du terme dans le document \n",
    "                        et en la divisant par le nombre total de mots dans le document.\n",
    "- Inverse Document Frequency (IDF): C'est une mesure de l'importance d'un terme dans l'ensemble du corpus. \n",
    "                                    Elle est calculée en prenant le logarithme du nombre total de documents \n",
    "                                    divisé par le nombre de documents contenant le terme en question. \n",
    "                                    Il diminue la pondération des termes qui apparaissent dans de nombreux documents.\n",
    "- TF-IDF : C'est le produit de TF et IDF. \n",
    "           Cela permet de mettre en évidence les termes qui sont importants dans un document donné\n",
    "           mais relativement rares dans le reste du corpus.\n",
    "\n",
    "\n",
    "- Recherche d'information: les termes les plus pertinents dans un document par rapport à une requête donnée.\n",
    "- Classification de texte: En convertissant les documents en vecteurs TF-IDF,\n",
    "                           on peut les utiliser comme entrées pour des algorithmes de classification.\n",
    "- Extraction de mots-clés: Les termes ayant les scores TF-IDF les plus élevés peuvent être considérés\n",
    "                           comme des mots-clés représentatifs du document.\n",
    "- Résumé automatique: TF-IDF peut aider à identifier les phrases les plus importantes d'un document\n",
    "                       pour en générer un résumé.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "reviews_df = pd.read_csv('../_data/Reviews.csv')\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  923     0     1    13  9389]\n",
      " [   91     5     1    11  5747]\n",
      " [   44     1    11    26  8403]\n",
      " [   26     4     4   156 15933]\n",
      " [   42    15    10    34 72801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.09      0.16     10326\n",
      "           2       0.20      0.00      0.00      5855\n",
      "           3       0.41      0.00      0.00      8485\n",
      "           4       0.65      0.01      0.02     16123\n",
      "           5       0.65      1.00      0.79     72902\n",
      "\n",
      "    accuracy                           0.65    113691\n",
      "   macro avg       0.55      0.22      0.19    113691\n",
      "weighted avg       0.62      0.65      0.52    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import sklearn.model_selection as skms\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = skms.train_test_split(tfidf_matrix, reviews_df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "naive_bayes = nb.fit(X_train, y_train)\n",
    "predicted = naive_bayes.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/lina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)  # Joining tokens into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "text_data_preprocessed = [preprocess_text(text) for text in reviews_df['Text']]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  458     0     0     3  9865]\n",
      " [   26     8     0     3  5818]\n",
      " [   19     1    10    10  8445]\n",
      " [    5     0     2   138 15978]\n",
      " [   15     6     3    20 72858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.04      0.08     10326\n",
      "           2       0.53      0.00      0.00      5855\n",
      "           3       0.67      0.00      0.00      8485\n",
      "           4       0.79      0.01      0.02     16123\n",
      "           5       0.64      1.00      0.78     72902\n",
      "\n",
      "    accuracy                           0.65    113691\n",
      "   macro avg       0.70      0.21      0.18    113691\n",
      "weighted avg       0.68      0.65      0.51    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = skms.train_test_split(tfidf_matrix, reviews_df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "naive_bayes = nb.fit(X_train, y_train)\n",
    "predicted = naive_bayes.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
