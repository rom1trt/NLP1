{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n- Term Frequency (TF) : C'est la fréquence d'un terme dans un document donné. \\n                        Elle est calculée en comptant le nombre d'occurrences du terme dans le document \\n                        et en la divisant par le nombre total de mots dans le document.\\n- Inverse Document Frequency (IDF): C'est une mesure de l'importance d'un terme dans l'ensemble du corpus. \\n                                    Elle est calculée en prenant le logarithme du nombre total de documents \\n                                    divisé par le nombre de documents contenant le terme en question. \\n                                    Il diminue la pondération des termes qui apparaissent dans de nombreux documents.\\n- TF-IDF : C'est le produit de TF et IDF. \\n           Cela permet de mettre en évidence les termes qui sont importants dans un document donné\\n           mais relativement rares dans le reste du corpus.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Term Frequency (TF) : C'est la fréquence d'un terme dans un document donné. \n",
    "                        Elle est calculée en comptant le nombre d'occurrences du terme dans le document \n",
    "                        et en la divisant par le nombre total de mots dans le document.\n",
    "- Inverse Document Frequency (IDF): C'est une mesure de l'importance d'un terme dans l'ensemble du corpus. \n",
    "                                    Elle est calculée en prenant le logarithme du nombre total de documents \n",
    "                                    divisé par le nombre de documents contenant le terme en question. \n",
    "                                    Il diminue la pondération des termes qui apparaissent dans de nombreux documents.\n",
    "- TF-IDF : C'est le produit de TF et IDF. \n",
    "           Cela permet de mettre en évidence les termes qui sont importants dans un document donné\n",
    "           mais relativement rares dans le reste du corpus.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('../_data/Reviews.csv')\n",
    "text_data = reviews_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)\n",
    "#feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n- Recherche d'information: les termes les plus pertinents dans un document par rapport à une requête donnée.\\n- Classification de texte: En convertissant les documents en vecteurs TF-IDF,\\n                           on peut les utiliser comme entrées pour des algorithmes de classification.\\n- Extraction de mots-clés: Les termes ayant les scores TF-IDF les plus élevés peuvent être considérés\\n                           comme des mots-clés représentatifs du document.\\n- Résumé automatique: TF-IDF peut aider à identifier les phrases les plus importantes d'un document\\n                       pour en générer un résumé.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Recherche d'information: les termes les plus pertinents dans un document par rapport à une requête donnée.\n",
    "- Classification de texte: En convertissant les documents en vecteurs TF-IDF,\n",
    "                           on peut les utiliser comme entrées pour des algorithmes de classification.\n",
    "- Extraction de mots-clés: Les termes ayant les scores TF-IDF les plus élevés peuvent être considérés\n",
    "                           comme des mots-clés représentatifs du document.\n",
    "- Résumé automatique: TF-IDF peut aider à identifier les phrases les plus importantes d'un document\n",
    "                       pour en générer un résumé.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  923     0     1    13  9389]\n",
      " [   91     5     1    11  5747]\n",
      " [   44     1    11    26  8403]\n",
      " [   26     4     4   156 15933]\n",
      " [   42    15    10    34 72801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.09      0.16     10326\n",
      "           2       0.20      0.00      0.00      5855\n",
      "           3       0.41      0.00      0.00      8485\n",
      "           4       0.65      0.01      0.02     16123\n",
      "           5       0.65      1.00      0.79     72902\n",
      "\n",
      "    accuracy                           0.65    113691\n",
      "   macro avg       0.55      0.22      0.19    113691\n",
      "weighted avg       0.62      0.65      0.52    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import sklearn.model_selection as skms\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = skms.train_test_split(tfidf_matrix, reviews_df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "naive_bayes = nb.fit(X_train, y_train)\n",
    "predicted = naive_bayes.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
