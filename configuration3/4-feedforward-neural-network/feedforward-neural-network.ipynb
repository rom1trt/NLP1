{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK TOKENIZER AND TF-IDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jean-\n",
      "[nltk_data]     michel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tokenizer import tokenizer\n",
    "from vectorizer import vectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../_data/Reviews.csv') # Loading the dataset\n",
    "X, y = data['Text'], data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X[:], y[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_documents = tokenizer(X.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, vect = vectorizer(tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data of length 568454 in batches of size 10000\n",
      "Processing batch from index 0 to 10000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 10000 to 20000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 20000 to 30000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 30000 to 40000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 40000 to 50000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 50000 to 60000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 60000 to 70000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 70000 to 80000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 80000 to 90000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 90000 to 100000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 100000 to 110000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 110000 to 120000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 120000 to 130000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 130000 to 140000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 140000 to 150000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 150000 to 160000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 160000 to 170000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 170000 to 180000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 180000 to 190000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 190000 to 200000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 200000 to 210000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 210000 to 220000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 220000 to 230000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 230000 to 240000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 240000 to 250000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 250000 to 260000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 260000 to 270000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 270000 to 280000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 280000 to 290000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 290000 to 300000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 300000 to 310000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 310000 to 320000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 320000 to 330000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 330000 to 340000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 340000 to 350000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 350000 to 360000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 360000 to 370000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 370000 to 380000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 380000 to 390000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 390000 to 400000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 400000 to 410000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 410000 to 420000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 420000 to 430000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 430000 to 440000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 440000 to 450000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 450000 to 460000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 460000 to 470000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 470000 to 480000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 480000 to 490000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 490000 to 500000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 500000 to 510000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 510000 to 520000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 520000 to 530000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 530000 to 540000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 540000 to 550000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 550000 to 560000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n",
      "Processing batch from index 560000 to 570000\n",
      "Number of tokens:  0\n",
      "Number of sentences:  0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "\n",
    "print(f\"Processing data of length {len(X)} in batches of size {batch_size}\")\n",
    "X_vect_batches = []\n",
    "for start in range(0, len(X), batch_size):\n",
    "    end = start + batch_size\n",
    "    print(f\"Processing batch from index {start} to {end}\")\n",
    "    batch_X = X[start:end].copy()\n",
    "    tokenized_documents = tokenizer(batch_X)\n",
    "    X_vect, _ = vectorizer(tokenized_documents)\n",
    "    # Store the processed batch\n",
    "    X_vect_batches.append(X_vect)\n",
    "\n",
    "X = np.vstack(X_vect_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454763, 300) (113691, 300) (454763,) (113691,)\n",
      "[0.69675133 0.46625919 0.19659357 0.54161421 0.49475396 0.68864423\n",
      " 0.77237797 0.61296189 0.64803631 0.67720143 0.53871329 0.43821322\n",
      " 0.57999926 0.60784278 0.64792152 0.49237756 0.62410983 0.48551687\n",
      " 0.66650609 0.6353156  0.28711372 0.57419198 0.26327911 0.58957649\n",
      " 0.58278467 0.46489851 0.33019595 0.34122713 0.50042139 0.47023063\n",
      " 0.23547583 0.40088003 0.36770556 0.21215492 0.44290871 0.29329761\n",
      " 0.39150614 0.41075528 0.67269826 0.2800273  0.59147843 0.74466023\n",
      " 0.64935439 0.45447142 0.53504712 0.59418841 0.35070694 0.20508571\n",
      " 0.42417751 0.48023969 0.40409482 0.63481863 0.44575853 0.45432337\n",
      " 0.44045728 0.50378316 0.26800294 0.76815876 0.40490527 0.42683939\n",
      " 0.6215097  0.43453887 0.51992281 0.53506951 0.58080606 0.52360652\n",
      " 0.54309204 0.47171951 0.43835253 0.65036521 0.4512514  0.70861387\n",
      " 0.63950446 0.58614768 0.42354527 0.74754527 0.66673732 0.70711648\n",
      " 0.60580582 0.34354116 0.45962957 0.76664349 0.34378702 0.61320123\n",
      " 0.4956486  0.39240117 0.70849181 0.48831415 0.39725638 0.60069362\n",
      " 0.67477945 0.75411397 0.69598337 0.45761375 0.50489262 0.7292554\n",
      " 0.36714932 0.48582472 0.62464008 0.61665476 0.32402418 0.23279358\n",
      " 0.16732475 0.5365093  0.34310048 0.60289579 0.35704663 0.28157099\n",
      " 0.56770297 0.51289975 0.30671711 0.54974155 0.18412016 0.35819873\n",
      " 0.5808177  0.37224233 0.46805587 0.56467199 0.38226579 0.56365775\n",
      " 0.60011138 0.73845589 0.45867492 0.30889995 0.31734329 0.2847545\n",
      " 0.7339889  0.37283075 0.57143923 0.59149958 0.69223533 0.40878394\n",
      " 0.4983859  0.5302026  0.69035307 0.21365922 0.21711166 0.45571632\n",
      " 0.43844874 0.28055356 0.64200365 0.36850874 0.41711452 0.62479364\n",
      " 0.71810632 0.45515862 0.57556119 0.44909957 0.41415817 0.44410013\n",
      " 0.40916465 0.42245089 0.67242001 0.27251318 0.58346022 0.49519269\n",
      " 0.49178464 0.41324719 0.6258591  0.27456207 0.64214537 0.34719716\n",
      " 0.41175559 0.37391764 0.65926323 0.83424034 0.46721616 0.47078838\n",
      " 0.72602999 0.37259429 0.63273893 0.62426877 0.71451839 0.3671752\n",
      " 0.37090362 0.48378003 0.48637465 0.42907834 0.57038422 0.63363001\n",
      " 0.65945927 0.29003696 0.28288615 0.31767723 0.66744275 0.66348146\n",
      " 0.39988797 0.43828422 0.36569693 0.53560439 0.58137645 0.38924596\n",
      " 0.57481625 0.75137877 0.77037739 0.46640775 0.42089594 0.52999974\n",
      " 0.37799634 0.60361853 0.44769482 0.65228554 0.74140473 0.46840697\n",
      " 0.57332229 0.82131501 0.46951631 0.50267088 0.14999    0.36981776\n",
      " 0.4817595  0.4373068  0.41752867 0.67327147 0.44226942 0.22245043\n",
      " 0.45032919 0.64339552 0.35232246 0.21938891 0.59381764 0.23487222\n",
      " 0.27487302 0.34235352 0.32922085 0.41090081 0.63312101 0.58452558\n",
      " 0.49136328 0.3999038  0.51946792 0.69070529 0.42191974 0.48360606\n",
      " 0.34664325 0.26453668 0.56894734 0.4482145  0.64092792 0.81541722\n",
      " 0.3849636  0.31058374 0.36895055 0.50387155 0.40263028 0.63799014\n",
      " 0.52124184 0.39624635 0.64089013 0.53213454 0.41525428 0.76692575\n",
      " 0.72011738 0.69701651 0.27638948 0.3298233  0.45862209 0.55994619\n",
      " 0.77894225 0.5117203  0.20578829 0.47886641 0.51921669 0.56912703\n",
      " 0.23745417 0.53454029 0.51384983 0.41615938 0.46988423 0.48096303\n",
      " 0.72748395 0.34939417 0.31502619 0.54111835 0.29923599 0.60124515\n",
      " 0.40881046 0.68766185 0.7966241  0.4679522  0.6455757  0.48485069\n",
      " 0.61512802 0.4408967  0.36467186 0.76844136 0.34028241 0.61460262\n",
      " 0.48084655 0.53648147 0.55653158 0.41603694 0.54797327 0.54597831\n",
      " 0.5687658  0.72684142 0.530299   0.41222903 0.51167561 0.70589562]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network\n",
    "### Model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 00:24:11.201302: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 00:24:11.294821: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 00:24:11.647464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 00:24:12.680625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint('model_best.keras', save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, min_lr=0.00001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, num_classes):\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            X_batch = X[start:end]\n",
    "            y_batch = to_categorical(y[start:end], num_classes=num_classes)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# Setup the model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(256)(inputs)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128)(x)\n",
    "x = LeakyReLU()(x)\n",
    "residual = Dense(64)(x)\n",
    "x = LeakyReLU()(residual)\n",
    "\n",
    "x = Dense(64)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Add()([x, residual])\n",
    "x = Dense(32)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(16)(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "outputs = Dense(np.max(y_train) + 1, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Define the generator\n",
    "train_generator = batch_generator(X_train, y_train, 32, np.max(y_train) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.6543 - loss: 0.9964 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m  153/14212\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 997us/step - accuracy: 0.6698 - loss: 0.9077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean-michel/Epita/nlp/.venv/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/jean-michel/Epita/nlp/.venv/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "/home/jean-michel/Epita/nlp/.venv/lib/python3.10/site-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.9023 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6757 - loss: 0.8897 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.6777 - loss: 0.8811 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6802 - loss: 0.8743 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6814 - loss: 0.8691 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6826 - loss: 0.8640 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.6844 - loss: 0.8594 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6854 - loss: 0.8549 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6865 - loss: 0.8513 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6874 - loss: 0.8478 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6888 - loss: 0.8444 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6899 - loss: 0.8414 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6902 - loss: 0.8383 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6918 - loss: 0.8356 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.6922 - loss: 0.8329 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.6934 - loss: 0.8301 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6938 - loss: 0.8277 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6946 - loss: 0.8252 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.6954 - loss: 0.8235 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6962 - loss: 0.8205 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6971 - loss: 0.8191 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.6979 - loss: 0.8169 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6979 - loss: 0.8149 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.6985 - loss: 0.8130 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.6995 - loss: 0.8112 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7000 - loss: 0.8086 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7007 - loss: 0.8070 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7018 - loss: 0.8051 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7017 - loss: 0.8037 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7027 - loss: 0.8014 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7033 - loss: 0.7995 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7033 - loss: 0.7982 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7041 - loss: 0.7960 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7047 - loss: 0.7952 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7056 - loss: 0.7932 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7052 - loss: 0.7923 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7061 - loss: 0.7898 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7069 - loss: 0.7888 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7075 - loss: 0.7876 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7073 - loss: 0.7855 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7077 - loss: 0.7841 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7089 - loss: 0.7831 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7094 - loss: 0.7814 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7099 - loss: 0.7807 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7104 - loss: 0.7785 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7108 - loss: 0.7768 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7121 - loss: 0.7761 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7121 - loss: 0.7745 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7123 - loss: 0.7741 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7126 - loss: 0.7726 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7130 - loss: 0.7708 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7139 - loss: 0.7693 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7145 - loss: 0.7683 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7147 - loss: 0.7670 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7156 - loss: 0.7653 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.7645 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7158 - loss: 0.7648 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7164 - loss: 0.7622 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7167 - loss: 0.7613 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7172 - loss: 0.7605 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7176 - loss: 0.7586 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7180 - loss: 0.7586 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7180 - loss: 0.7576 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7184 - loss: 0.7564 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7196 - loss: 0.7543 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7194 - loss: 0.7550 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7210 - loss: 0.7525 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.7524 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7198 - loss: 0.7511 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7205 - loss: 0.7502 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.7481 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.7468 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7234 - loss: 0.7463 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.7459 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.7447 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7223 - loss: 0.7441 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7238 - loss: 0.7417 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.7415 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7245 - loss: 0.7403 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7252 - loss: 0.7398 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.7385 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7256 - loss: 0.7372 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.7371 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7269 - loss: 0.7361 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.7263 - loss: 0.7353 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7275 - loss: 0.7345 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7280 - loss: 0.7329 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7277 - loss: 0.7324 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7275 - loss: 0.7316 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7282 - loss: 0.7317 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7283 - loss: 0.7302 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7286 - loss: 0.7295 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7286 - loss: 0.7289 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7288 - loss: 0.7278 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7292 - loss: 0.7276 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7296 - loss: 0.7264 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7299 - loss: 0.7259 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.7303 - loss: 0.7251 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a0a118f96f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int(np.ceil(X_train.shape[0] / 32)),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = batch_generator(X_test, y_test, batch_size=32, num_classes=np.max(y_train) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 788us/step\n",
      "Confusion Matrix:\n",
      "[[ 5982   525   228   193  3398]\n",
      " [ 1322   924   463   430  2716]\n",
      " [  903   503  1115  1199  4765]\n",
      " [  456   207   489  2591 12380]\n",
      " [  886   183   311  1186 70336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.58      0.60     10326\n",
      "           2       0.39      0.16      0.23      5855\n",
      "           3       0.43      0.13      0.20      8485\n",
      "           4       0.46      0.16      0.24     16123\n",
      "           5       0.75      0.96      0.84     72902\n",
      "\n",
      "    accuracy                           0.71    113691\n",
      "   macro avg       0.53      0.40      0.42    113691\n",
      "weighted avg       0.66      0.71      0.66    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions_prob = model.predict(test_generator, steps=int(np.ceil(X_test.shape[0] / 32)))\n",
    "predictions = np.argmax(predictions_prob, axis=1)\n",
    "\n",
    "# Metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model with current date and time in model folder\n",
    "\n",
    "# Create a folder named _models in the current directory\n",
    "if not os.path.exists('_models'):\n",
    "    os.makedirs('_models')\n",
    "    \n",
    "model.save(f'_models/config3_feedforward_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
